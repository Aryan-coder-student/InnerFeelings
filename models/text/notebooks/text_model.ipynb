{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7e5c6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os \n",
    "PATH_TRAIN = os.path.join(\"..\",\"data\",\"train_data_ext\",\"train.csv\")\n",
    "PATH_TEST = os.path.join(\"..\",\"data\",\"train_data_ext\",\"test.csv\")\n",
    "PATH_VAL = os.path.join(\"..\",\"data\",\"train_data_ext\",\"val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1ebdec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(PATH_TRAIN)\n",
    "test_data = pd.read_csv(PATH_TEST)\n",
    "val_data = pd.read_csv(PATH_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3ead1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I didn't feel humiliated, which was a surprise...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I didn't feel humiliated, which was a surprise...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm grabbing a minute to post because I feel i...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    label\n",
       "0  I didn't feel humiliated, which was a surprise...  sadness\n",
       "1  I didn't feel humiliated, which was a surprise...  sadness\n",
       "2  I can go from feeling so hopeless to so damned...  sadness\n",
       "3  I'm grabbing a minute to post because I feel i...    anger\n",
       "4  I am ever feeling nostalgic about the fireplac...     love"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8adb40da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acfc377e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I didn't feel humiliated, which was a surprise...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm grabbing a minute to post because I feel i...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I am feeling extremely grouchy today, and to b...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    label\n",
       "0  I didn't feel humiliated, which was a surprise...  sadness\n",
       "2  I can go from feeling so hopeless to so damned...  sadness\n",
       "3  I'm grabbing a minute to post because I feel i...    anger\n",
       "4  I am ever feeling nostalgic about the fireplac...     love\n",
       "5  I am feeling extremely grouchy today, and to b...    anger"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd7f9946",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_2_class = {0: 'sadness', 1: 'joy', 2: 'love', 3: 'anger', 4: 'fear', 5: 'surprise'}\n",
    "class_2_idx = {value: key for key, value in idx_2_class.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a38dd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_11768\\1271200801.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_data[\"labels\"] = train_data[\"label\"].replace(class_2_idx)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_11768\\1271200801.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_data[\"labels\"] = test_data[\"label\"].replace(class_2_idx)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_11768\\1271200801.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  val_data[\"labels\"] = val_data[\"label\"].replace(class_2_idx)\n"
     ]
    }
   ],
   "source": [
    "train_data[\"labels\"] = train_data[\"label\"].replace(class_2_idx)\n",
    "test_data[\"labels\"] = test_data[\"label\"].replace(class_2_idx)\n",
    "val_data[\"labels\"] = val_data[\"label\"].replace(class_2_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd041a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03019a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I didn't feel humiliated, which was a surprise...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm grabbing a minute to post because I feel i...</td>\n",
       "      <td>anger</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I am feeling extremely grouchy today, and to b...</td>\n",
       "      <td>anger</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>I feel incredibly thankful for the lessons I'm...</td>\n",
       "      <td>joy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>I feel such a profound and unshakeable longing...</td>\n",
       "      <td>love</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>I feel distinctly called in Clermont to focus ...</td>\n",
       "      <td>love</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>I hope you can feel glad that she gave you so ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>I'm feeling pretty worthless right now, like I...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text    label  labels\n",
       "0    I didn't feel humiliated, which was a surprise...  sadness       0\n",
       "2    I can go from feeling so hopeless to so damned...  sadness       0\n",
       "3    I'm grabbing a minute to post because I feel i...    anger       3\n",
       "4    I am ever feeling nostalgic about the fireplac...     love       2\n",
       "5    I am feeling extremely grouchy today, and to b...    anger       3\n",
       "..                                                 ...      ...     ...\n",
       "395  I feel incredibly thankful for the lessons I'm...      joy       1\n",
       "396  I feel such a profound and unshakeable longing...     love       2\n",
       "397  I feel distinctly called in Clermont to focus ...     love       2\n",
       "398  I hope you can feel glad that she gave you so ...      joy       1\n",
       "399  I'm feeling pretty worthless right now, like I...  sadness       0\n",
       "\n",
       "[399 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d0cde72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "ds_train = Dataset.from_pandas(train_data)\n",
    "ds_test = Dataset.from_pandas(test_data)\n",
    "ds_val = Dataset.from_pandas(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5d025aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train.remove_columns(['__index_level_0__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3a0d5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'labels'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8195d3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import (\n",
    "     AutoTokenizer,\n",
    "    AutoModelForSequenceClassification ,\n",
    ")\n",
    "import torch \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_id = \"answerdotai/ModernBERT-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id,cache_dir=\"../modernbert_tokenizer_cache\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccfdc6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0 \n",
    "def find_max_len(paragraph):\n",
    "    global max_len\n",
    "    len_sentence = len(paragraph)\n",
    "    max_len = max(max_len, len_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "782663a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length =8024 # 27814\n",
    "# max_output_length = 8\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68fc81a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c28be9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_to_model_inputs(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1f9a14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d9355302e14e468c8a8e7c172c99f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/399 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f88ab70037b494fb9fbc2dba3fbab10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = ds_train.map(\n",
    "    process_data_to_model_inputs,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "val_dataset = ds_val.map(\n",
    "    process_data_to_model_inputs,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f503f10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aeab62be88f49618d71cb8fcc4141e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = ds_test.map(\n",
    "    process_data_to_model_inputs,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5f7a302",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    ")\n",
    "val_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    ")\n",
    "\n",
    "test_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "094b4b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I didn't feel humiliated, which was a surprise...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm grabbing a minute to post because I feel i...</td>\n",
       "      <td>anger</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I am feeling extremely grouchy today, and to b...</td>\n",
       "      <td>anger</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>I feel incredibly thankful for the lessons I'm...</td>\n",
       "      <td>joy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>I feel such a profound and unshakeable longing...</td>\n",
       "      <td>love</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>I feel distinctly called in Clermont to focus ...</td>\n",
       "      <td>love</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>I hope you can feel glad that she gave you so ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>I'm feeling pretty worthless right now, like I...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text    label  labels\n",
       "0    I didn't feel humiliated, which was a surprise...  sadness       0\n",
       "2    I can go from feeling so hopeless to so damned...  sadness       0\n",
       "3    I'm grabbing a minute to post because I feel i...    anger       3\n",
       "4    I am ever feeling nostalgic about the fireplac...     love       2\n",
       "5    I am feeling extremely grouchy today, and to b...    anger       3\n",
       "..                                                 ...      ...     ...\n",
       "395  I feel incredibly thankful for the lessons I'm...      joy       1\n",
       "396  I feel such a profound and unshakeable longing...     love       2\n",
       "397  I feel distinctly called in Clermont to focus ...     love       2\n",
       "398  I hope you can feel glad that she gave you so ...      joy       1\n",
       "399  I'm feeling pretty worthless right now, like I...  sadness       0\n",
       "\n",
       "[399 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3cf57ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "292aede29d9f4af898e9a658e98a7ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/399 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b228f1de42942728098b7350e73f036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "027846c2ac494323a22bb50aecfb8ff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Value \n",
    "train_dataset = train_dataset.cast_column(\"labels\", Value(\"int64\"))\n",
    "val_dataset = val_dataset.cast_column(\"labels\", Value(\"int64\"))\n",
    "test_dataset = test_dataset.cast_column(\"labels\", Value(\"int64\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eadfb907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = len(idx_2_class)\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "070883b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "from peft import prepare_model_for_kbit_training,LoraConfig,PeftModel,get_peft_model\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=\"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2dec75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --user https://huggingface.co/madbuda/triton-windows-builds/resolve/main/triton-3.0.0-cp310-cp310-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fd0e66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2631e9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf4b3f7268d44d1884d33c4bc2abd1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/599M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\python_file_install\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in E:\\Panipat\\WEPI\\aryan\\aryan\\models\\text\\Modern_Bert\\models--answerdotai--ModernBERT-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "robert_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_id,\n",
    "    cache_dir=\"../Modern_Bert/modern_bert\",\n",
    "    # quantization_config=bnb_config,          \n",
    "    id2label=idx_2_class,\n",
    "    label2id=class_2_idx,\n",
    "    num_labels=num_labels  \n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "705041f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model\n",
      "model.embeddings\n",
      "model.embeddings.tok_embeddings\n",
      "model.embeddings.norm\n",
      "model.embeddings.drop\n",
      "model.layers\n",
      "model.layers.0\n",
      "model.layers.0.attn_norm\n",
      "model.layers.0.attn\n",
      "model.layers.0.attn.Wqkv\n",
      "model.layers.0.attn.rotary_emb\n",
      "model.layers.0.attn.Wo\n",
      "model.layers.0.attn.out_drop\n",
      "model.layers.0.mlp_norm\n",
      "model.layers.0.mlp\n",
      "model.layers.0.mlp.Wi\n",
      "model.layers.0.mlp.act\n",
      "model.layers.0.mlp.drop\n",
      "model.layers.0.mlp.Wo\n",
      "model.layers.1\n",
      "model.layers.1.attn_norm\n",
      "model.layers.1.attn\n",
      "model.layers.1.attn.Wqkv\n",
      "model.layers.1.attn.rotary_emb\n",
      "model.layers.1.attn.Wo\n",
      "model.layers.1.attn.out_drop\n",
      "model.layers.1.mlp_norm\n",
      "model.layers.1.mlp\n",
      "model.layers.1.mlp.Wi\n",
      "model.layers.1.mlp.act\n",
      "model.layers.1.mlp.drop\n",
      "model.layers.1.mlp.Wo\n",
      "model.layers.2\n",
      "model.layers.2.attn_norm\n",
      "model.layers.2.attn\n",
      "model.layers.2.attn.Wqkv\n",
      "model.layers.2.attn.rotary_emb\n",
      "model.layers.2.attn.Wo\n",
      "model.layers.2.attn.out_drop\n",
      "model.layers.2.mlp_norm\n",
      "model.layers.2.mlp\n",
      "model.layers.2.mlp.Wi\n",
      "model.layers.2.mlp.act\n",
      "model.layers.2.mlp.drop\n",
      "model.layers.2.mlp.Wo\n",
      "model.layers.3\n",
      "model.layers.3.attn_norm\n",
      "model.layers.3.attn\n",
      "model.layers.3.attn.Wqkv\n",
      "model.layers.3.attn.rotary_emb\n",
      "model.layers.3.attn.Wo\n",
      "model.layers.3.attn.out_drop\n",
      "model.layers.3.mlp_norm\n",
      "model.layers.3.mlp\n",
      "model.layers.3.mlp.Wi\n",
      "model.layers.3.mlp.act\n",
      "model.layers.3.mlp.drop\n",
      "model.layers.3.mlp.Wo\n",
      "model.layers.4\n",
      "model.layers.4.attn_norm\n",
      "model.layers.4.attn\n",
      "model.layers.4.attn.Wqkv\n",
      "model.layers.4.attn.rotary_emb\n",
      "model.layers.4.attn.Wo\n",
      "model.layers.4.attn.out_drop\n",
      "model.layers.4.mlp_norm\n",
      "model.layers.4.mlp\n",
      "model.layers.4.mlp.Wi\n",
      "model.layers.4.mlp.act\n",
      "model.layers.4.mlp.drop\n",
      "model.layers.4.mlp.Wo\n",
      "model.layers.5\n",
      "model.layers.5.attn_norm\n",
      "model.layers.5.attn\n",
      "model.layers.5.attn.Wqkv\n",
      "model.layers.5.attn.rotary_emb\n",
      "model.layers.5.attn.Wo\n",
      "model.layers.5.attn.out_drop\n",
      "model.layers.5.mlp_norm\n",
      "model.layers.5.mlp\n",
      "model.layers.5.mlp.Wi\n",
      "model.layers.5.mlp.act\n",
      "model.layers.5.mlp.drop\n",
      "model.layers.5.mlp.Wo\n",
      "model.layers.6\n",
      "model.layers.6.attn_norm\n",
      "model.layers.6.attn\n",
      "model.layers.6.attn.Wqkv\n",
      "model.layers.6.attn.rotary_emb\n",
      "model.layers.6.attn.Wo\n",
      "model.layers.6.attn.out_drop\n",
      "model.layers.6.mlp_norm\n",
      "model.layers.6.mlp\n",
      "model.layers.6.mlp.Wi\n",
      "model.layers.6.mlp.act\n",
      "model.layers.6.mlp.drop\n",
      "model.layers.6.mlp.Wo\n",
      "model.layers.7\n",
      "model.layers.7.attn_norm\n",
      "model.layers.7.attn\n",
      "model.layers.7.attn.Wqkv\n",
      "model.layers.7.attn.rotary_emb\n",
      "model.layers.7.attn.Wo\n",
      "model.layers.7.attn.out_drop\n",
      "model.layers.7.mlp_norm\n",
      "model.layers.7.mlp\n",
      "model.layers.7.mlp.Wi\n",
      "model.layers.7.mlp.act\n",
      "model.layers.7.mlp.drop\n",
      "model.layers.7.mlp.Wo\n",
      "model.layers.8\n",
      "model.layers.8.attn_norm\n",
      "model.layers.8.attn\n",
      "model.layers.8.attn.Wqkv\n",
      "model.layers.8.attn.rotary_emb\n",
      "model.layers.8.attn.Wo\n",
      "model.layers.8.attn.out_drop\n",
      "model.layers.8.mlp_norm\n",
      "model.layers.8.mlp\n",
      "model.layers.8.mlp.Wi\n",
      "model.layers.8.mlp.act\n",
      "model.layers.8.mlp.drop\n",
      "model.layers.8.mlp.Wo\n",
      "model.layers.9\n",
      "model.layers.9.attn_norm\n",
      "model.layers.9.attn\n",
      "model.layers.9.attn.Wqkv\n",
      "model.layers.9.attn.rotary_emb\n",
      "model.layers.9.attn.Wo\n",
      "model.layers.9.attn.out_drop\n",
      "model.layers.9.mlp_norm\n",
      "model.layers.9.mlp\n",
      "model.layers.9.mlp.Wi\n",
      "model.layers.9.mlp.act\n",
      "model.layers.9.mlp.drop\n",
      "model.layers.9.mlp.Wo\n",
      "model.layers.10\n",
      "model.layers.10.attn_norm\n",
      "model.layers.10.attn\n",
      "model.layers.10.attn.Wqkv\n",
      "model.layers.10.attn.rotary_emb\n",
      "model.layers.10.attn.Wo\n",
      "model.layers.10.attn.out_drop\n",
      "model.layers.10.mlp_norm\n",
      "model.layers.10.mlp\n",
      "model.layers.10.mlp.Wi\n",
      "model.layers.10.mlp.act\n",
      "model.layers.10.mlp.drop\n",
      "model.layers.10.mlp.Wo\n",
      "model.layers.11\n",
      "model.layers.11.attn_norm\n",
      "model.layers.11.attn\n",
      "model.layers.11.attn.Wqkv\n",
      "model.layers.11.attn.rotary_emb\n",
      "model.layers.11.attn.Wo\n",
      "model.layers.11.attn.out_drop\n",
      "model.layers.11.mlp_norm\n",
      "model.layers.11.mlp\n",
      "model.layers.11.mlp.Wi\n",
      "model.layers.11.mlp.act\n",
      "model.layers.11.mlp.drop\n",
      "model.layers.11.mlp.Wo\n",
      "model.layers.12\n",
      "model.layers.12.attn_norm\n",
      "model.layers.12.attn\n",
      "model.layers.12.attn.Wqkv\n",
      "model.layers.12.attn.rotary_emb\n",
      "model.layers.12.attn.Wo\n",
      "model.layers.12.attn.out_drop\n",
      "model.layers.12.mlp_norm\n",
      "model.layers.12.mlp\n",
      "model.layers.12.mlp.Wi\n",
      "model.layers.12.mlp.act\n",
      "model.layers.12.mlp.drop\n",
      "model.layers.12.mlp.Wo\n",
      "model.layers.13\n",
      "model.layers.13.attn_norm\n",
      "model.layers.13.attn\n",
      "model.layers.13.attn.Wqkv\n",
      "model.layers.13.attn.rotary_emb\n",
      "model.layers.13.attn.Wo\n",
      "model.layers.13.attn.out_drop\n",
      "model.layers.13.mlp_norm\n",
      "model.layers.13.mlp\n",
      "model.layers.13.mlp.Wi\n",
      "model.layers.13.mlp.act\n",
      "model.layers.13.mlp.drop\n",
      "model.layers.13.mlp.Wo\n",
      "model.layers.14\n",
      "model.layers.14.attn_norm\n",
      "model.layers.14.attn\n",
      "model.layers.14.attn.Wqkv\n",
      "model.layers.14.attn.rotary_emb\n",
      "model.layers.14.attn.Wo\n",
      "model.layers.14.attn.out_drop\n",
      "model.layers.14.mlp_norm\n",
      "model.layers.14.mlp\n",
      "model.layers.14.mlp.Wi\n",
      "model.layers.14.mlp.act\n",
      "model.layers.14.mlp.drop\n",
      "model.layers.14.mlp.Wo\n",
      "model.layers.15\n",
      "model.layers.15.attn_norm\n",
      "model.layers.15.attn\n",
      "model.layers.15.attn.Wqkv\n",
      "model.layers.15.attn.rotary_emb\n",
      "model.layers.15.attn.Wo\n",
      "model.layers.15.attn.out_drop\n",
      "model.layers.15.mlp_norm\n",
      "model.layers.15.mlp\n",
      "model.layers.15.mlp.Wi\n",
      "model.layers.15.mlp.act\n",
      "model.layers.15.mlp.drop\n",
      "model.layers.15.mlp.Wo\n",
      "model.layers.16\n",
      "model.layers.16.attn_norm\n",
      "model.layers.16.attn\n",
      "model.layers.16.attn.Wqkv\n",
      "model.layers.16.attn.rotary_emb\n",
      "model.layers.16.attn.Wo\n",
      "model.layers.16.attn.out_drop\n",
      "model.layers.16.mlp_norm\n",
      "model.layers.16.mlp\n",
      "model.layers.16.mlp.Wi\n",
      "model.layers.16.mlp.act\n",
      "model.layers.16.mlp.drop\n",
      "model.layers.16.mlp.Wo\n",
      "model.layers.17\n",
      "model.layers.17.attn_norm\n",
      "model.layers.17.attn\n",
      "model.layers.17.attn.Wqkv\n",
      "model.layers.17.attn.rotary_emb\n",
      "model.layers.17.attn.Wo\n",
      "model.layers.17.attn.out_drop\n",
      "model.layers.17.mlp_norm\n",
      "model.layers.17.mlp\n",
      "model.layers.17.mlp.Wi\n",
      "model.layers.17.mlp.act\n",
      "model.layers.17.mlp.drop\n",
      "model.layers.17.mlp.Wo\n",
      "model.layers.18\n",
      "model.layers.18.attn_norm\n",
      "model.layers.18.attn\n",
      "model.layers.18.attn.Wqkv\n",
      "model.layers.18.attn.rotary_emb\n",
      "model.layers.18.attn.Wo\n",
      "model.layers.18.attn.out_drop\n",
      "model.layers.18.mlp_norm\n",
      "model.layers.18.mlp\n",
      "model.layers.18.mlp.Wi\n",
      "model.layers.18.mlp.act\n",
      "model.layers.18.mlp.drop\n",
      "model.layers.18.mlp.Wo\n",
      "model.layers.19\n",
      "model.layers.19.attn_norm\n",
      "model.layers.19.attn\n",
      "model.layers.19.attn.Wqkv\n",
      "model.layers.19.attn.rotary_emb\n",
      "model.layers.19.attn.Wo\n",
      "model.layers.19.attn.out_drop\n",
      "model.layers.19.mlp_norm\n",
      "model.layers.19.mlp\n",
      "model.layers.19.mlp.Wi\n",
      "model.layers.19.mlp.act\n",
      "model.layers.19.mlp.drop\n",
      "model.layers.19.mlp.Wo\n",
      "model.layers.20\n",
      "model.layers.20.attn_norm\n",
      "model.layers.20.attn\n",
      "model.layers.20.attn.Wqkv\n",
      "model.layers.20.attn.rotary_emb\n",
      "model.layers.20.attn.Wo\n",
      "model.layers.20.attn.out_drop\n",
      "model.layers.20.mlp_norm\n",
      "model.layers.20.mlp\n",
      "model.layers.20.mlp.Wi\n",
      "model.layers.20.mlp.act\n",
      "model.layers.20.mlp.drop\n",
      "model.layers.20.mlp.Wo\n",
      "model.layers.21\n",
      "model.layers.21.attn_norm\n",
      "model.layers.21.attn\n",
      "model.layers.21.attn.Wqkv\n",
      "model.layers.21.attn.rotary_emb\n",
      "model.layers.21.attn.Wo\n",
      "model.layers.21.attn.out_drop\n",
      "model.layers.21.mlp_norm\n",
      "model.layers.21.mlp\n",
      "model.layers.21.mlp.Wi\n",
      "model.layers.21.mlp.act\n",
      "model.layers.21.mlp.drop\n",
      "model.layers.21.mlp.Wo\n",
      "model.final_norm\n",
      "head\n",
      "head.dense\n",
      "head.act\n",
      "head.norm\n",
      "drop\n",
      "classifier\n"
     ]
    }
   ],
   "source": [
    "for name, module in robert_model.named_modules():\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9bafb1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2876b667",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\n",
    "        \"Wqkv\",    # The combined QKV projection linear layer in attention\n",
    "        \"Wo\",      # Attention output projection linear layer\n",
    "        \"mlp.Wi\",  # MLP (feed-forward) input linear layer\n",
    "        \"mlp.Wo\",  # MLP output linear layer\n",
    "    ],\n",
    "\n",
    ")\n",
    "roberta_model_1 = prepare_model_for_kbit_training(robert_model)\n",
    "model = get_peft_model(robert_model, config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0af2635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 399\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e266c64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    accuracy_metric = evaluate.load(\"accuracy\")\n",
    "    f1_metric = evaluate.load(\"f1\")\n",
    "    \n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy[\"accuracy\"],\n",
    "        \"f1\": f1[\"f1\"],\n",
    "        \"eval_loss\": eval_pred.loss if hasattr(eval_pred, \"loss\") else None  # Optional: include loss\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d95da3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../modern-bert\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-3,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a5df281",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=roberta_model_1,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e778c67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] WON'T CONVERT compiled_embeddings f:\\python_file_install\\lib\\site-packages\\transformers\\models\\modernbert\\modeling_modernbert.py line 206 \n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] due to: \n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1164, in __call__\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 547, in __call__\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _compile(\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 986, in _compile\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in compile_inner\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_utils_internal.py\", line 95, in wrapper_function\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 750, in _compile_inner\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 231, in _fn\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 662, in transform\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     tracer.run()\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2868, in run\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     super().run()\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1052, in run\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     while self.step():\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 962, in step\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._return(inst)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3033, in _return\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1101, in compile_subgraph\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1432, in call_user_compiler\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 130, in __call__\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\__init__.py\", line 2340, in __call__\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1863, in compile_fx\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return aot_autograd(\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 83, in __call__\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 203, in aot_dispatch_base\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 489, in __call__\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return inner_compile(\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 102, in debug_wrapper\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 2027, in compile_to_module\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 2033, in _compile_to_module\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1968, in codegen\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.scheduler.codegen()\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3477, in codegen\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._codegen()\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3554, in _codegen\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.get_backend(device).codegen_node(node)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\cuda_combined_scheduling.py\", line 80, in codegen_node\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._triton_scheduling.codegen_node(node)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\simd.py\", line 1219, in codegen_node\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.codegen_node_schedule(\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\simd.py\", line 1263, in codegen_node_schedule\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     src_code = kernel.codegen_kernel()\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\triton.py\", line 3154, in codegen_kernel\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     **self.inductor_meta_common(),\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\triton.py\", line 3013, in inductor_meta_common\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     \"backend_hash\": torch.utils._triton.triton_hash_with_backend(),\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\utils\\_triton.py\", line 111, in triton_hash_with_backend\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     backend = triton_backend()\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\utils\\_triton.py\", line 103, in triton_backend\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     target = driver.active.get_current_target()\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\runtime\\driver.py\", line 23, in __getattr__\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._initialize_obj()\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\runtime\\driver.py\", line 20, in _initialize_obj\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._obj = self._init_fn()\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\runtime\\driver.py\", line 9, in _create_driver\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return actives[0]()\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 412, in __init__\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.utils = CudaUtils()  # TODO: make static\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 90, in __init__\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     mod = compile_module_from_src(Path(os.path.join(dirname, \"driver.c\")).read_text(), \"cuda_utils\")\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 67, in compile_module_from_src\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 51, in library_dirs\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return [libdevice_dir, *libcuda_dirs()]\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 24, in libcuda_dirs\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return [os.path.join(cuda_path, \"lib\", \"x64\")]\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\ntpath.py\", line 104, in join\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     path = os.fspath(path)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] \n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] \n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1164, in __call__\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 547, in __call__\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _compile(\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 986, in _compile\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in compile_inner\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_utils_internal.py\", line 95, in wrapper_function\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 750, in _compile_inner\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 231, in _fn\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 662, in transform\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     tracer.run()\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2868, in run\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     super().run()\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1052, in run\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     while self.step():\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 962, in step\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._return(inst)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3033, in _return\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1101, in compile_subgraph\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1432, in call_user_compiler\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 130, in __call__\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\__init__.py\", line 2340, in __call__\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1863, in compile_fx\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return aot_autograd(\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 83, in __call__\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 203, in aot_dispatch_base\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 489, in __call__\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return inner_compile(\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 102, in debug_wrapper\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 2027, in compile_to_module\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 2033, in _compile_to_module\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1968, in codegen\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.scheduler.codegen()\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3477, in codegen\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._codegen()\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3554, in _codegen\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.get_backend(device).codegen_node(node)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\cuda_combined_scheduling.py\", line 80, in codegen_node\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._triton_scheduling.codegen_node(node)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\simd.py\", line 1219, in codegen_node\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.codegen_node_schedule(\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\simd.py\", line 1263, in codegen_node_schedule\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     src_code = kernel.codegen_kernel()\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\triton.py\", line 3154, in codegen_kernel\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     **self.inductor_meta_common(),\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\triton.py\", line 3013, in inductor_meta_common\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     \"backend_hash\": torch.utils._triton.triton_hash_with_backend(),\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\utils\\_triton.py\", line 111, in triton_hash_with_backend\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     backend = triton_backend()\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\utils\\_triton.py\", line 103, in triton_backend\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     target = driver.active.get_current_target()\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\runtime\\driver.py\", line 23, in __getattr__\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._initialize_obj()\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\runtime\\driver.py\", line 20, in _initialize_obj\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._obj = self._init_fn()\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\runtime\\driver.py\", line 9, in _create_driver\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return actives[0]()\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 412, in __init__\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.utils = CudaUtils()  # TODO: make static\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 90, in __init__\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     mod = compile_module_from_src(Path(os.path.join(dirname, \"driver.c\")).read_text(), \"cuda_utils\")\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 67, in compile_module_from_src\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 51, in library_dirs\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return [libdevice_dir, *libcuda_dirs()]\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 24, in libcuda_dirs\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return [os.path.join(cuda_path, \"lib\", \"x64\")]\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\ntpath.py\", line 104, in join\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     path = os.fspath(path)\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] \n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0809 09:39:23.535000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] \n",
      "f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py:194: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n",
      "W0809 09:39:27.433000 11768 site-packages\\torch\\_inductor\\utils.py:1137] [1/0] Not enough SMs to use max_autotune_gemm mode\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] WON'T CONVERT compiled_mlp f:\\python_file_install\\lib\\site-packages\\transformers\\models\\modernbert\\modeling_modernbert.py line 525 \n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] due to: \n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1164, in __call__\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 547, in __call__\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _compile(\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 986, in _compile\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in compile_inner\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_utils_internal.py\", line 95, in wrapper_function\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 750, in _compile_inner\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 231, in _fn\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 662, in transform\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     tracer.run()\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2868, in run\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     super().run()\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1052, in run\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     while self.step():\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 962, in step\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._return(inst)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3033, in _return\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1101, in compile_subgraph\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1432, in call_user_compiler\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 130, in __call__\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\__init__.py\", line 2340, in __call__\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1863, in compile_fx\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return aot_autograd(\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 83, in __call__\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 489, in __call__\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return inner_compile(\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 102, in debug_wrapper\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 2027, in compile_to_module\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 2033, in _compile_to_module\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1968, in codegen\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.scheduler.codegen()\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3477, in codegen\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._codegen()\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3554, in _codegen\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.get_backend(device).codegen_node(node)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\cuda_combined_scheduling.py\", line 80, in codegen_node\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._triton_scheduling.codegen_node(node)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\simd.py\", line 1219, in codegen_node\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.codegen_node_schedule(\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\simd.py\", line 1263, in codegen_node_schedule\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     src_code = kernel.codegen_kernel()\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\triton.py\", line 3154, in codegen_kernel\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     **self.inductor_meta_common(),\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\triton.py\", line 3013, in inductor_meta_common\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     \"backend_hash\": torch.utils._triton.triton_hash_with_backend(),\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\utils\\_triton.py\", line 111, in triton_hash_with_backend\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     backend = triton_backend()\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\utils\\_triton.py\", line 103, in triton_backend\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     target = driver.active.get_current_target()\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\runtime\\driver.py\", line 23, in __getattr__\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._initialize_obj()\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\runtime\\driver.py\", line 20, in _initialize_obj\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._obj = self._init_fn()\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\runtime\\driver.py\", line 9, in _create_driver\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return actives[0]()\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 412, in __init__\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.utils = CudaUtils()  # TODO: make static\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 90, in __init__\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     mod = compile_module_from_src(Path(os.path.join(dirname, \"driver.c\")).read_text(), \"cuda_utils\")\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 67, in compile_module_from_src\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 51, in library_dirs\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return [libdevice_dir, *libcuda_dirs()]\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 24, in libcuda_dirs\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return [os.path.join(cuda_path, \"lib\", \"x64\")]\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\ntpath.py\", line 104, in join\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     path = os.fspath(path)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] \n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] \n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1164, in __call__\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 547, in __call__\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _compile(\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 986, in _compile\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in compile_inner\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_utils_internal.py\", line 95, in wrapper_function\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 750, in _compile_inner\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 231, in _fn\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 662, in transform\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     tracer.run()\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2868, in run\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     super().run()\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1052, in run\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     while self.step():\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 962, in step\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._return(inst)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3033, in _return\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1101, in compile_subgraph\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1432, in call_user_compiler\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 130, in __call__\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\__init__.py\", line 2340, in __call__\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1863, in compile_fx\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return aot_autograd(\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 83, in __call__\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 489, in __call__\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return inner_compile(\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 102, in debug_wrapper\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 2027, in compile_to_module\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 2033, in _compile_to_module\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1968, in codegen\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.scheduler.codegen()\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3477, in codegen\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._codegen()\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3554, in _codegen\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.get_backend(device).codegen_node(node)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\cuda_combined_scheduling.py\", line 80, in codegen_node\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._triton_scheduling.codegen_node(node)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\simd.py\", line 1219, in codegen_node\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.codegen_node_schedule(\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\simd.py\", line 1263, in codegen_node_schedule\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     src_code = kernel.codegen_kernel()\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\triton.py\", line 3154, in codegen_kernel\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     **self.inductor_meta_common(),\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\triton.py\", line 3013, in inductor_meta_common\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     \"backend_hash\": torch.utils._triton.triton_hash_with_backend(),\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\utils\\_triton.py\", line 111, in triton_hash_with_backend\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     backend = triton_backend()\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\utils\\_triton.py\", line 103, in triton_backend\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     target = driver.active.get_current_target()\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\runtime\\driver.py\", line 23, in __getattr__\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._initialize_obj()\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\runtime\\driver.py\", line 20, in _initialize_obj\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._obj = self._init_fn()\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\runtime\\driver.py\", line 9, in _create_driver\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return actives[0]()\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 412, in __init__\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.utils = CudaUtils()  # TODO: make static\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 90, in __init__\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     mod = compile_module_from_src(Path(os.path.join(dirname, \"driver.c\")).read_text(), \"cuda_utils\")\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 67, in compile_module_from_src\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 51, in library_dirs\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return [libdevice_dir, *libcuda_dirs()]\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 24, in libcuda_dirs\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return [os.path.join(cuda_path, \"lib\", \"x64\")]\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\ntpath.py\", line 104, in join\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     path = os.fspath(path)\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] \n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0809 09:39:27.550000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] \n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] WON'T CONVERT forward f:\\python_file_install\\lib\\site-packages\\transformers\\models\\modernbert\\modeling_modernbert.py line 239 \n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] due to: \n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1164, in __call__\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 547, in __call__\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _compile(\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 986, in _compile\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in compile_inner\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_utils_internal.py\", line 95, in wrapper_function\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 750, in _compile_inner\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 231, in _fn\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 662, in transform\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     tracer.run()\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2868, in run\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     super().run()\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1052, in run\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     while self.step():\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 962, in step\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._return(inst)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3033, in _return\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1101, in compile_subgraph\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1432, in call_user_compiler\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 130, in __call__\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\__init__.py\", line 2340, in __call__\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1863, in compile_fx\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return aot_autograd(\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 83, in __call__\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 489, in __call__\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return inner_compile(\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 102, in debug_wrapper\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 2027, in compile_to_module\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 2033, in _compile_to_module\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1968, in codegen\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.scheduler.codegen()\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3477, in codegen\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._codegen()\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3554, in _codegen\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.get_backend(device).codegen_node(node)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\cuda_combined_scheduling.py\", line 80, in codegen_node\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._triton_scheduling.codegen_node(node)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\simd.py\", line 1219, in codegen_node\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.codegen_node_schedule(\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\simd.py\", line 1263, in codegen_node_schedule\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     src_code = kernel.codegen_kernel()\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\triton.py\", line 3154, in codegen_kernel\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     **self.inductor_meta_common(),\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\triton.py\", line 3013, in inductor_meta_common\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     \"backend_hash\": torch.utils._triton.triton_hash_with_backend(),\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\utils\\_triton.py\", line 111, in triton_hash_with_backend\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     backend = triton_backend()\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\utils\\_triton.py\", line 103, in triton_backend\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     target = driver.active.get_current_target()\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\runtime\\driver.py\", line 23, in __getattr__\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._initialize_obj()\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\runtime\\driver.py\", line 20, in _initialize_obj\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._obj = self._init_fn()\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\runtime\\driver.py\", line 9, in _create_driver\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return actives[0]()\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 412, in __init__\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.utils = CudaUtils()  # TODO: make static\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 90, in __init__\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     mod = compile_module_from_src(Path(os.path.join(dirname, \"driver.c\")).read_text(), \"cuda_utils\")\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 67, in compile_module_from_src\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 51, in library_dirs\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return [libdevice_dir, *libcuda_dirs()]\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 24, in libcuda_dirs\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return [os.path.join(cuda_path, \"lib\", \"x64\")]\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\ntpath.py\", line 104, in join\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     path = os.fspath(path)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] \n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] \n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1164, in __call__\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 547, in __call__\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _compile(\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 986, in _compile\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in compile_inner\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_utils_internal.py\", line 95, in wrapper_function\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 750, in _compile_inner\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 231, in _fn\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 662, in transform\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     tracer.run()\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2868, in run\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     super().run()\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1052, in run\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     while self.step():\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 962, in step\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._return(inst)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3033, in _return\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1101, in compile_subgraph\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1432, in call_user_compiler\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 130, in __call__\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\__init__.py\", line 2340, in __call__\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1863, in compile_fx\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return aot_autograd(\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 83, in __call__\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 489, in __call__\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return inner_compile(\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 102, in debug_wrapper\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 2027, in compile_to_module\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 2033, in _compile_to_module\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1968, in codegen\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.scheduler.codegen()\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3477, in codegen\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._codegen()\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3554, in _codegen\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.get_backend(device).codegen_node(node)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\cuda_combined_scheduling.py\", line 80, in codegen_node\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._triton_scheduling.codegen_node(node)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\simd.py\", line 1219, in codegen_node\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.codegen_node_schedule(\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\simd.py\", line 1263, in codegen_node_schedule\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     src_code = kernel.codegen_kernel()\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\triton.py\", line 3154, in codegen_kernel\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     **self.inductor_meta_common(),\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\triton.py\", line 3013, in inductor_meta_common\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     \"backend_hash\": torch.utils._triton.triton_hash_with_backend(),\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\utils\\_triton.py\", line 111, in triton_hash_with_backend\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     backend = triton_backend()\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\utils\\_triton.py\", line 103, in triton_backend\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     target = driver.active.get_current_target()\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\runtime\\driver.py\", line 23, in __getattr__\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._initialize_obj()\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\runtime\\driver.py\", line 20, in _initialize_obj\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._obj = self._init_fn()\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\runtime\\driver.py\", line 9, in _create_driver\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return actives[0]()\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 412, in __init__\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.utils = CudaUtils()  # TODO: make static\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 90, in __init__\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     mod = compile_module_from_src(Path(os.path.join(dirname, \"driver.c\")).read_text(), \"cuda_utils\")\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 67, in compile_module_from_src\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 51, in library_dirs\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return [libdevice_dir, *libcuda_dirs()]\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 24, in libcuda_dirs\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return [os.path.join(cuda_path, \"lib\", \"x64\")]\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\ntpath.py\", line 104, in join\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     path = os.fspath(path)\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] \n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0809 09:39:28.197000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] \n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] WON'T CONVERT forward f:\\python_file_install\\lib\\site-packages\\peft\\tuners\\lora\\layer.py line 744 \n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] due to: \n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1164, in __call__\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 547, in __call__\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _compile(\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 986, in _compile\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in compile_inner\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_utils_internal.py\", line 95, in wrapper_function\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 750, in _compile_inner\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 231, in _fn\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 662, in transform\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     tracer.run()\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2868, in run\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     super().run()\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1052, in run\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     while self.step():\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 962, in step\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._return(inst)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3033, in _return\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1101, in compile_subgraph\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1432, in call_user_compiler\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 130, in __call__\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\__init__.py\", line 2340, in __call__\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1863, in compile_fx\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return aot_autograd(\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 83, in __call__\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 489, in __call__\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return inner_compile(\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 102, in debug_wrapper\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 2027, in compile_to_module\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 2033, in _compile_to_module\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1968, in codegen\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.scheduler.codegen()\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3477, in codegen\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._codegen()\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3554, in _codegen\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.get_backend(device).codegen_node(node)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\cuda_combined_scheduling.py\", line 80, in codegen_node\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._triton_scheduling.codegen_node(node)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\simd.py\", line 1219, in codegen_node\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.codegen_node_schedule(\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\simd.py\", line 1263, in codegen_node_schedule\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     src_code = kernel.codegen_kernel()\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\triton.py\", line 3154, in codegen_kernel\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     **self.inductor_meta_common(),\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\triton.py\", line 3013, in inductor_meta_common\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     \"backend_hash\": torch.utils._triton.triton_hash_with_backend(),\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\utils\\_triton.py\", line 111, in triton_hash_with_backend\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     backend = triton_backend()\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\utils\\_triton.py\", line 103, in triton_backend\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     target = driver.active.get_current_target()\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\runtime\\driver.py\", line 23, in __getattr__\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._initialize_obj()\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\runtime\\driver.py\", line 20, in _initialize_obj\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._obj = self._init_fn()\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\runtime\\driver.py\", line 9, in _create_driver\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return actives[0]()\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 412, in __init__\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.utils = CudaUtils()  # TODO: make static\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 90, in __init__\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     mod = compile_module_from_src(Path(os.path.join(dirname, \"driver.c\")).read_text(), \"cuda_utils\")\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 67, in compile_module_from_src\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 51, in library_dirs\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return [libdevice_dir, *libcuda_dirs()]\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 24, in libcuda_dirs\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return [os.path.join(cuda_path, \"lib\", \"x64\")]\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\ntpath.py\", line 104, in join\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     path = os.fspath(path)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] \n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] \n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1164, in __call__\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 547, in __call__\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _compile(\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 986, in _compile\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in compile_inner\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_utils_internal.py\", line 95, in wrapper_function\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 750, in _compile_inner\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 231, in _fn\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 662, in transform\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     tracer.run()\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2868, in run\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     super().run()\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1052, in run\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     while self.step():\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 962, in step\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._return(inst)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3033, in _return\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1101, in compile_subgraph\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1432, in call_user_compiler\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 130, in __call__\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\__init__.py\", line 2340, in __call__\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1863, in compile_fx\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return aot_autograd(\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 83, in __call__\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 489, in __call__\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return inner_compile(\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 102, in debug_wrapper\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 2027, in compile_to_module\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 2033, in _compile_to_module\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1968, in codegen\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.scheduler.codegen()\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3477, in codegen\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._codegen()\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3554, in _codegen\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.get_backend(device).codegen_node(node)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\cuda_combined_scheduling.py\", line 80, in codegen_node\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._triton_scheduling.codegen_node(node)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\simd.py\", line 1219, in codegen_node\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.codegen_node_schedule(\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\simd.py\", line 1263, in codegen_node_schedule\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     src_code = kernel.codegen_kernel()\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\triton.py\", line 3154, in codegen_kernel\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     **self.inductor_meta_common(),\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\triton.py\", line 3013, in inductor_meta_common\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     \"backend_hash\": torch.utils._triton.triton_hash_with_backend(),\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\utils\\_triton.py\", line 111, in triton_hash_with_backend\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     backend = triton_backend()\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\utils\\_triton.py\", line 103, in triton_backend\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     target = driver.active.get_current_target()\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\runtime\\driver.py\", line 23, in __getattr__\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._initialize_obj()\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\runtime\\driver.py\", line 20, in _initialize_obj\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._obj = self._init_fn()\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\runtime\\driver.py\", line 9, in _create_driver\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return actives[0]()\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 412, in __init__\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.utils = CudaUtils()  # TODO: make static\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 90, in __init__\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     mod = compile_module_from_src(Path(os.path.join(dirname, \"driver.c\")).read_text(), \"cuda_utils\")\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 67, in compile_module_from_src\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 51, in library_dirs\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return [libdevice_dir, *libcuda_dirs()]\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 24, in libcuda_dirs\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return [os.path.join(cuda_path, \"lib\", \"x64\")]\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\ntpath.py\", line 104, in join\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     path = os.fspath(path)\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] \n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0809 09:39:28.507000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] \n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] WON'T CONVERT forward f:\\python_file_install\\lib\\site-packages\\transformers\\activations.py line 68 \n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] due to: \n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1164, in __call__\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 547, in __call__\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _compile(\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 986, in _compile\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in compile_inner\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_utils_internal.py\", line 95, in wrapper_function\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 750, in _compile_inner\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 231, in _fn\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 662, in transform\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     tracer.run()\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2868, in run\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     super().run()\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1052, in run\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     while self.step():\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 962, in step\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._return(inst)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3033, in _return\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1101, in compile_subgraph\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1432, in call_user_compiler\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 130, in __call__\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\__init__.py\", line 2340, in __call__\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1863, in compile_fx\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return aot_autograd(\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 83, in __call__\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 489, in __call__\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return inner_compile(\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 102, in debug_wrapper\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 2027, in compile_to_module\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 2033, in _compile_to_module\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1968, in codegen\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.scheduler.codegen()\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3477, in codegen\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._codegen()\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3554, in _codegen\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.get_backend(device).codegen_node(node)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\cuda_combined_scheduling.py\", line 80, in codegen_node\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._triton_scheduling.codegen_node(node)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\simd.py\", line 1219, in codegen_node\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.codegen_node_schedule(\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\simd.py\", line 1263, in codegen_node_schedule\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     src_code = kernel.codegen_kernel()\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\triton.py\", line 3154, in codegen_kernel\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     **self.inductor_meta_common(),\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\triton.py\", line 3013, in inductor_meta_common\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     \"backend_hash\": torch.utils._triton.triton_hash_with_backend(),\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\utils\\_triton.py\", line 111, in triton_hash_with_backend\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     backend = triton_backend()\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\utils\\_triton.py\", line 103, in triton_backend\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     target = driver.active.get_current_target()\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\runtime\\driver.py\", line 23, in __getattr__\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._initialize_obj()\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\runtime\\driver.py\", line 20, in _initialize_obj\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._obj = self._init_fn()\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\runtime\\driver.py\", line 9, in _create_driver\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return actives[0]()\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 412, in __init__\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.utils = CudaUtils()  # TODO: make static\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 90, in __init__\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     mod = compile_module_from_src(Path(os.path.join(dirname, \"driver.c\")).read_text(), \"cuda_utils\")\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 67, in compile_module_from_src\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 51, in library_dirs\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return [libdevice_dir, *libcuda_dirs()]\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 24, in libcuda_dirs\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return [os.path.join(cuda_path, \"lib\", \"x64\")]\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\ntpath.py\", line 104, in join\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     path = os.fspath(path)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] \n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] \n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1164, in __call__\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 547, in __call__\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _compile(\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 986, in _compile\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in compile_inner\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_utils_internal.py\", line 95, in wrapper_function\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 750, in _compile_inner\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 231, in _fn\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 662, in transform\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     tracer.run()\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2868, in run\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     super().run()\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1052, in run\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     while self.step():\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 962, in step\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._return(inst)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3033, in _return\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1101, in compile_subgraph\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1432, in call_user_compiler\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 130, in __call__\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\__init__.py\", line 2340, in __call__\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1863, in compile_fx\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return aot_autograd(\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 83, in __call__\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 489, in __call__\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return inner_compile(\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 102, in debug_wrapper\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 2027, in compile_to_module\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 2033, in _compile_to_module\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1968, in codegen\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.scheduler.codegen()\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3477, in codegen\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._codegen()\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3554, in _codegen\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.get_backend(device).codegen_node(node)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\cuda_combined_scheduling.py\", line 80, in codegen_node\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._triton_scheduling.codegen_node(node)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\simd.py\", line 1219, in codegen_node\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.codegen_node_schedule(\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\simd.py\", line 1263, in codegen_node_schedule\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     src_code = kernel.codegen_kernel()\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\triton.py\", line 3154, in codegen_kernel\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     **self.inductor_meta_common(),\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\_inductor\\codegen\\triton.py\", line 3013, in inductor_meta_common\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     \"backend_hash\": torch.utils._triton.triton_hash_with_backend(),\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\utils\\_triton.py\", line 111, in triton_hash_with_backend\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     backend = triton_backend()\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\site-packages\\torch\\utils\\_triton.py\", line 103, in triton_backend\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     target = driver.active.get_current_target()\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\runtime\\driver.py\", line 23, in __getattr__\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._initialize_obj()\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\runtime\\driver.py\", line 20, in _initialize_obj\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._obj = self._init_fn()\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\runtime\\driver.py\", line 9, in _create_driver\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return actives[0]()\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 412, in __init__\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.utils = CudaUtils()  # TODO: make static\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 90, in __init__\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     mod = compile_module_from_src(Path(os.path.join(dirname, \"driver.c\")).read_text(), \"cuda_utils\")\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 67, in compile_module_from_src\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     so = _build(name, src_path, tmpdir, library_dirs(), include_dir, libraries)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 51, in library_dirs\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return [libdevice_dir, *libcuda_dirs()]\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python310\\site-packages\\triton\\backends\\nvidia\\driver.py\", line 24, in libcuda_dirs\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return [os.path.join(cuda_path, \"lib\", \"x64\")]\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"f:\\python_file_install\\lib\\ntpath.py\", line 104, in join\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233]     path = os.fspath(path)\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] \n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0809 09:39:28.849000 11768 site-packages\\torch\\_dynamo\\convert_frame.py:1233] \n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.16 GiB is allocated by PyTorch, and 275.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ensure label column is int for all datasets\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\python_file_install\\lib\\site-packages\\transformers\\trainer.py:2237\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2235\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2236\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2238\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2242\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\python_file_install\\lib\\site-packages\\transformers\\trainer.py:2578\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2571\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2572\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2573\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2574\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[0;32m   2575\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2576\u001b[0m )\n\u001b[0;32m   2577\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2578\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2581\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2582\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2583\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2584\u001b[0m ):\n\u001b[0;32m   2585\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2586\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mf:\\python_file_install\\lib\\site-packages\\transformers\\trainer.py:3792\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[0;32m   3789\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 3792\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3794\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[0;32m   3795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   3796\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3797\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   3798\u001b[0m ):\n",
      "File \u001b[1;32mf:\\python_file_install\\lib\\site-packages\\transformers\\trainer.py:3879\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[0;32m   3877\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[0;32m   3878\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m-> 3879\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m   3880\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   3881\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   3882\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mf:\\python_file_install\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mf:\\python_file_install\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mf:\\python_file_install\\lib\\site-packages\\transformers\\models\\modernbert\\modeling_modernbert.py:1146\u001b[0m, in \u001b[0;36mModernBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, sliding_window_mask, position_ids, inputs_embeds, labels, indices, cu_seqlens, max_seqlen, batch_size, seq_len, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1143\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_set_compile()\n\u001b[1;32m-> 1146\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43msliding_window_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msliding_window_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcu_seqlens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcu_seqlens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_seqlen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_seqlen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1160\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1161\u001b[0m last_hidden_state \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mclassifier_pooling \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mf:\\python_file_install\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mf:\\python_file_install\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mf:\\python_file_install\\lib\\site-packages\\transformers\\models\\modernbert\\modeling_modernbert.py:861\u001b[0m, in \u001b[0;36mModernBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, sliding_window_mask, position_ids, inputs_embeds, indices, cu_seqlens, max_seqlen, batch_size, seq_len, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[0;32m    859\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_states,)\n\u001b[1;32m--> 861\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mencoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[43msliding_window_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msliding_window_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcu_seqlens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcu_seqlens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_seqlen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_seqlen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(layer_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mf:\\python_file_install\\lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mf:\\python_file_install\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mf:\\python_file_install\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mf:\\python_file_install\\lib\\site-packages\\transformers\\models\\modernbert\\modeling_modernbert.py:550\u001b[0m, in \u001b[0;36mModernBertEncoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, sliding_window_mask, position_ids, cu_seqlens, max_seqlen, output_attentions)\u001b[0m\n\u001b[0;32m    539\u001b[0m attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_norm(hidden_states),\n\u001b[0;32m    541\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    546\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    547\u001b[0m )\n\u001b[0;32m    548\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    549\u001b[0m mlp_output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 550\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompiled_mlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mreference_compile\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_norm(hidden_states))\n\u001b[0;32m    553\u001b[0m )\n\u001b[0;32m    554\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m mlp_output\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (hidden_states,) \u001b[38;5;241m+\u001b[39m attn_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[1;32mf:\\python_file_install\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:574\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    569\u001b[0m saved_dynamic_layer_stack_depth \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    570\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_functorch\u001b[38;5;241m.\u001b[39mget_dynamic_layer_stack_depth()\n\u001b[0;32m    571\u001b[0m )\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;66;03m# Restore the dynamic layer stack depth if necessary.\u001b[39;00m\n\u001b[0;32m    577\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_functorch\u001b[38;5;241m.\u001b[39mpop_dynamic_layer_stack_and_undo_to_depth(\n\u001b[0;32m    578\u001b[0m         saved_dynamic_layer_stack_depth\n\u001b[0;32m    579\u001b[0m     )\n",
      "File \u001b[1;32mf:\\python_file_install\\lib\\site-packages\\transformers\\models\\modernbert\\modeling_modernbert.py:527\u001b[0m, in \u001b[0;36mModernBertEncoderLayer.compiled_mlp\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mcompile(dynamic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    526\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompiled_mlp\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\python_file_install\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mf:\\python_file_install\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mf:\\python_file_install\\lib\\site-packages\\transformers\\models\\modernbert\\modeling_modernbert.py:240\u001b[0m, in \u001b[0;36mModernBertMLP.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 240\u001b[0m     \u001b[38;5;28minput\u001b[39m, gate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWo(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28minput\u001b[39m) \u001b[38;5;241m*\u001b[39m gate))\n",
      "File \u001b[1;32mf:\\python_file_install\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mf:\\python_file_install\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mf:\\python_file_install\\lib\\site-packages\\peft\\tuners\\lora\\layer.py:771\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    769\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cast_input_dtype(x, lora_A\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m active_adapter \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlora_variant:  \u001b[38;5;66;03m# vanilla LoRA\u001b[39;00m\n\u001b[1;32m--> 771\u001b[0m     result \u001b[38;5;241m=\u001b[39m result \u001b[38;5;241m+\u001b[39m \u001b[43mlora_B\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlora_A\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscaling\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    773\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlora_variant[active_adapter]\u001b[38;5;241m.\u001b[39mforward(\n\u001b[0;32m    774\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    775\u001b[0m         active_adapter\u001b[38;5;241m=\u001b[39mactive_adapter,\n\u001b[0;32m    776\u001b[0m         x\u001b[38;5;241m=\u001b[39mx,\n\u001b[0;32m    777\u001b[0m         result\u001b[38;5;241m=\u001b[39mresult,\n\u001b[0;32m    778\u001b[0m     )\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.16 GiB is allocated by PyTorch, and 275.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Ensure label column is int for all datasets\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea81d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\python_file_install\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9955605864524841,\n",
       " 'eval_accuracy': 0.635,\n",
       " 'eval_f1': 0.5444059102524209,\n",
       " 'eval_runtime': 26.3795,\n",
       " 'eval_samples_per_second': 7.582,\n",
       " 'eval_steps_per_second': 0.948,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4c2960",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\python_file_install\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "results = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbdb5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.65, 'f1': 0.5664597115348405, 'eval_loss': None}\n"
     ]
    }
   ],
   "source": [
    "logits = results.predictions\n",
    "labels = results.label_ids\n",
    "metrics = compute_metrics((logits, labels))\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c7e773",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = os.path.join(\"..\" , \"text_save_model\", \"modernbert_model_4\")\n",
    "os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "# robert_model.save_model(SAVE_PATH)\n",
    "trainer.save_model(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e4474f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ..\\text_save_model\\xlm_robert_model_3 were not used when initializing XLMRobertaForSequenceClassification: ['classifier.out_proj.base_layer.bias', 'classifier.out_proj.base_layer.weight', 'classifier.out_proj.lora_A.default.weight', 'classifier.out_proj.lora_B.default.weight', 'roberta.encoder.layer.0.attention.self.key.base_layer.bias', 'roberta.encoder.layer.0.attention.self.key.base_layer.weight', 'roberta.encoder.layer.0.attention.self.key.lora_A.default.weight', 'roberta.encoder.layer.0.attention.self.key.lora_B.default.weight', 'roberta.encoder.layer.0.attention.self.query.base_layer.bias', 'roberta.encoder.layer.0.attention.self.query.base_layer.weight', 'roberta.encoder.layer.0.attention.self.query.lora_A.default.weight', 'roberta.encoder.layer.0.attention.self.query.lora_B.default.weight', 'roberta.encoder.layer.0.attention.self.value.base_layer.bias', 'roberta.encoder.layer.0.attention.self.value.base_layer.weight', 'roberta.encoder.layer.0.attention.self.value.lora_A.default.weight', 'roberta.encoder.layer.0.attention.self.value.lora_B.default.weight', 'roberta.encoder.layer.1.attention.self.key.base_layer.bias', 'roberta.encoder.layer.1.attention.self.key.base_layer.weight', 'roberta.encoder.layer.1.attention.self.key.lora_A.default.weight', 'roberta.encoder.layer.1.attention.self.key.lora_B.default.weight', 'roberta.encoder.layer.1.attention.self.query.base_layer.bias', 'roberta.encoder.layer.1.attention.self.query.base_layer.weight', 'roberta.encoder.layer.1.attention.self.query.lora_A.default.weight', 'roberta.encoder.layer.1.attention.self.query.lora_B.default.weight', 'roberta.encoder.layer.1.attention.self.value.base_layer.bias', 'roberta.encoder.layer.1.attention.self.value.base_layer.weight', 'roberta.encoder.layer.1.attention.self.value.lora_A.default.weight', 'roberta.encoder.layer.1.attention.self.value.lora_B.default.weight', 'roberta.encoder.layer.10.attention.self.key.base_layer.bias', 'roberta.encoder.layer.10.attention.self.key.base_layer.weight', 'roberta.encoder.layer.10.attention.self.key.lora_A.default.weight', 'roberta.encoder.layer.10.attention.self.key.lora_B.default.weight', 'roberta.encoder.layer.10.attention.self.query.base_layer.bias', 'roberta.encoder.layer.10.attention.self.query.base_layer.weight', 'roberta.encoder.layer.10.attention.self.query.lora_A.default.weight', 'roberta.encoder.layer.10.attention.self.query.lora_B.default.weight', 'roberta.encoder.layer.10.attention.self.value.base_layer.bias', 'roberta.encoder.layer.10.attention.self.value.base_layer.weight', 'roberta.encoder.layer.10.attention.self.value.lora_A.default.weight', 'roberta.encoder.layer.10.attention.self.value.lora_B.default.weight', 'roberta.encoder.layer.11.attention.self.key.base_layer.bias', 'roberta.encoder.layer.11.attention.self.key.base_layer.weight', 'roberta.encoder.layer.11.attention.self.key.lora_A.default.weight', 'roberta.encoder.layer.11.attention.self.key.lora_B.default.weight', 'roberta.encoder.layer.11.attention.self.query.base_layer.bias', 'roberta.encoder.layer.11.attention.self.query.base_layer.weight', 'roberta.encoder.layer.11.attention.self.query.lora_A.default.weight', 'roberta.encoder.layer.11.attention.self.query.lora_B.default.weight', 'roberta.encoder.layer.11.attention.self.value.base_layer.bias', 'roberta.encoder.layer.11.attention.self.value.base_layer.weight', 'roberta.encoder.layer.11.attention.self.value.lora_A.default.weight', 'roberta.encoder.layer.11.attention.self.value.lora_B.default.weight', 'roberta.encoder.layer.2.attention.self.key.base_layer.bias', 'roberta.encoder.layer.2.attention.self.key.base_layer.weight', 'roberta.encoder.layer.2.attention.self.key.lora_A.default.weight', 'roberta.encoder.layer.2.attention.self.key.lora_B.default.weight', 'roberta.encoder.layer.2.attention.self.query.base_layer.bias', 'roberta.encoder.layer.2.attention.self.query.base_layer.weight', 'roberta.encoder.layer.2.attention.self.query.lora_A.default.weight', 'roberta.encoder.layer.2.attention.self.query.lora_B.default.weight', 'roberta.encoder.layer.2.attention.self.value.base_layer.bias', 'roberta.encoder.layer.2.attention.self.value.base_layer.weight', 'roberta.encoder.layer.2.attention.self.value.lora_A.default.weight', 'roberta.encoder.layer.2.attention.self.value.lora_B.default.weight', 'roberta.encoder.layer.3.attention.self.key.base_layer.bias', 'roberta.encoder.layer.3.attention.self.key.base_layer.weight', 'roberta.encoder.layer.3.attention.self.key.lora_A.default.weight', 'roberta.encoder.layer.3.attention.self.key.lora_B.default.weight', 'roberta.encoder.layer.3.attention.self.query.base_layer.bias', 'roberta.encoder.layer.3.attention.self.query.base_layer.weight', 'roberta.encoder.layer.3.attention.self.query.lora_A.default.weight', 'roberta.encoder.layer.3.attention.self.query.lora_B.default.weight', 'roberta.encoder.layer.3.attention.self.value.base_layer.bias', 'roberta.encoder.layer.3.attention.self.value.base_layer.weight', 'roberta.encoder.layer.3.attention.self.value.lora_A.default.weight', 'roberta.encoder.layer.3.attention.self.value.lora_B.default.weight', 'roberta.encoder.layer.4.attention.self.key.base_layer.bias', 'roberta.encoder.layer.4.attention.self.key.base_layer.weight', 'roberta.encoder.layer.4.attention.self.key.lora_A.default.weight', 'roberta.encoder.layer.4.attention.self.key.lora_B.default.weight', 'roberta.encoder.layer.4.attention.self.query.base_layer.bias', 'roberta.encoder.layer.4.attention.self.query.base_layer.weight', 'roberta.encoder.layer.4.attention.self.query.lora_A.default.weight', 'roberta.encoder.layer.4.attention.self.query.lora_B.default.weight', 'roberta.encoder.layer.4.attention.self.value.base_layer.bias', 'roberta.encoder.layer.4.attention.self.value.base_layer.weight', 'roberta.encoder.layer.4.attention.self.value.lora_A.default.weight', 'roberta.encoder.layer.4.attention.self.value.lora_B.default.weight', 'roberta.encoder.layer.5.attention.self.key.base_layer.bias', 'roberta.encoder.layer.5.attention.self.key.base_layer.weight', 'roberta.encoder.layer.5.attention.self.key.lora_A.default.weight', 'roberta.encoder.layer.5.attention.self.key.lora_B.default.weight', 'roberta.encoder.layer.5.attention.self.query.base_layer.bias', 'roberta.encoder.layer.5.attention.self.query.base_layer.weight', 'roberta.encoder.layer.5.attention.self.query.lora_A.default.weight', 'roberta.encoder.layer.5.attention.self.query.lora_B.default.weight', 'roberta.encoder.layer.5.attention.self.value.base_layer.bias', 'roberta.encoder.layer.5.attention.self.value.base_layer.weight', 'roberta.encoder.layer.5.attention.self.value.lora_A.default.weight', 'roberta.encoder.layer.5.attention.self.value.lora_B.default.weight', 'roberta.encoder.layer.6.attention.self.key.base_layer.bias', 'roberta.encoder.layer.6.attention.self.key.base_layer.weight', 'roberta.encoder.layer.6.attention.self.key.lora_A.default.weight', 'roberta.encoder.layer.6.attention.self.key.lora_B.default.weight', 'roberta.encoder.layer.6.attention.self.query.base_layer.bias', 'roberta.encoder.layer.6.attention.self.query.base_layer.weight', 'roberta.encoder.layer.6.attention.self.query.lora_A.default.weight', 'roberta.encoder.layer.6.attention.self.query.lora_B.default.weight', 'roberta.encoder.layer.6.attention.self.value.base_layer.bias', 'roberta.encoder.layer.6.attention.self.value.base_layer.weight', 'roberta.encoder.layer.6.attention.self.value.lora_A.default.weight', 'roberta.encoder.layer.6.attention.self.value.lora_B.default.weight', 'roberta.encoder.layer.7.attention.self.key.base_layer.bias', 'roberta.encoder.layer.7.attention.self.key.base_layer.weight', 'roberta.encoder.layer.7.attention.self.key.lora_A.default.weight', 'roberta.encoder.layer.7.attention.self.key.lora_B.default.weight', 'roberta.encoder.layer.7.attention.self.query.base_layer.bias', 'roberta.encoder.layer.7.attention.self.query.base_layer.weight', 'roberta.encoder.layer.7.attention.self.query.lora_A.default.weight', 'roberta.encoder.layer.7.attention.self.query.lora_B.default.weight', 'roberta.encoder.layer.7.attention.self.value.base_layer.bias', 'roberta.encoder.layer.7.attention.self.value.base_layer.weight', 'roberta.encoder.layer.7.attention.self.value.lora_A.default.weight', 'roberta.encoder.layer.7.attention.self.value.lora_B.default.weight', 'roberta.encoder.layer.8.attention.self.key.base_layer.bias', 'roberta.encoder.layer.8.attention.self.key.base_layer.weight', 'roberta.encoder.layer.8.attention.self.key.lora_A.default.weight', 'roberta.encoder.layer.8.attention.self.key.lora_B.default.weight', 'roberta.encoder.layer.8.attention.self.query.base_layer.bias', 'roberta.encoder.layer.8.attention.self.query.base_layer.weight', 'roberta.encoder.layer.8.attention.self.query.lora_A.default.weight', 'roberta.encoder.layer.8.attention.self.query.lora_B.default.weight', 'roberta.encoder.layer.8.attention.self.value.base_layer.bias', 'roberta.encoder.layer.8.attention.self.value.base_layer.weight', 'roberta.encoder.layer.8.attention.self.value.lora_A.default.weight', 'roberta.encoder.layer.8.attention.self.value.lora_B.default.weight', 'roberta.encoder.layer.9.attention.self.key.base_layer.bias', 'roberta.encoder.layer.9.attention.self.key.base_layer.weight', 'roberta.encoder.layer.9.attention.self.key.lora_A.default.weight', 'roberta.encoder.layer.9.attention.self.key.lora_B.default.weight', 'roberta.encoder.layer.9.attention.self.query.base_layer.bias', 'roberta.encoder.layer.9.attention.self.query.base_layer.weight', 'roberta.encoder.layer.9.attention.self.query.lora_A.default.weight', 'roberta.encoder.layer.9.attention.self.query.lora_B.default.weight', 'roberta.encoder.layer.9.attention.self.value.base_layer.bias', 'roberta.encoder.layer.9.attention.self.value.base_layer.weight', 'roberta.encoder.layer.9.attention.self.value.lora_A.default.weight', 'roberta.encoder.layer.9.attention.self.value.lora_B.default.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at ..\\text_save_model\\xlm_robert_model_3 and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.9.attention.self.value.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): XLMRobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(SAVE_PATH).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ee1212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I didn't feel humiliated, which was a surprise to me, considering the circumstances that had just unfolded, and as I reflected on it, I realized that it was a testament to my growth and resilience, and it made me think about all the times I had felt humiliated in the past, and how it had affected me, and I had to admit that it was a pretty terrible feeling, and one that I didn't wish on anyone, but at the same time, I was grateful that I had been able to navigate this situation without feeling that way, and it made me wonder if I had finally reached a point where I was comfortable with myself, and wasn't as concerned with what others thought of me, and that was a pretty liberating feeling, and it made me think about the concept of humiliation, and how it can be used as a tool to control and manipulate people, and how it can be used to make someone feel small and powerless, and it was interesting to me that I had been able to avoid feeling that way, even in a situation where I could have easily felt that way, and it made me feel a sense of pride and accomplishment, and it was a good feeling, but at the same time, it was also a bit of a confusing feeling, because I wasn't sure if I should be feeling proud of myself for not feeling humiliated, or if I should be feeling concerned that I wasn't feeling humiliated, and that maybe I should be feeling more emotional, and it was a weird feeling, not knowing how to process it, but as I sat there, thinking about it, I realized that maybe it was okay to just feel okay, and not feel the need to analyze it too much, and maybe it was just a sign that I was healing, and moving forward, and that was a good thing, and I felt a sense of sadness wash over me, not because I was humiliated, but because I had wasted so much time in the past letting other people's opinions dictate how I felt about myself, and I had let their words and actions have so much power over me, and it was a sad thing to think about, but it was also a liberating thing, because it meant that I had the power to change, and to move forward, and to not let those things affect me anymore, and that was a really good feeling, and it was a feeling that I was grateful for, and it was a reminder that I was strong, and capable, and resilient, and that I could get through anything, and that was a wonderful feeling, and one that I would carry with me for a long time.\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca9fd7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"label\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c34176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label id: tensor([[ 0.1209,  0.0660, -0.1847, -0.0564,  0.3370,  0.0738]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "text = train_data[\"text\"][0]\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "inputs = {k: v.to(device) for k,v in inputs.items()}\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predictions = logits\n",
    "\n",
    "print(\"Predicted label id:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923b22c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
