{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4a1e37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install librosa\n",
    "# !pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95805c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, APIRouter, UploadFile, File, HTTPException\n",
    "import librosa\n",
    "import io\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2FeatureExtractor\n",
    "import os\n",
    "\n",
    " \n",
    "app = FastAPI()\n",
    "voice_router = APIRouter()\n",
    "\n",
    "path_model = os.path.join(\"..\", \"Voice_model/\")\n",
    "model_name = \"prithivMLmods/Speech-Emotion-Classification\"\n",
    "model = Wav2Vec2ForSequenceClassification.from_pretrained(model_name, cache_dir=path_model)\n",
    "processor = Wav2Vec2FeatureExtractor.from_pretrained(model_name, cache_dir=path_model)\n",
    "\n",
    "id2label = {\n",
    "    \"0\": \"Anger\",\n",
    "    \"1\": \"Calm\",\n",
    "    \"2\": \"Disgust\",\n",
    "    \"3\": \"Fear\",\n",
    "    \"4\": \"Happy\",\n",
    "    \"5\": \"Neutral\",\n",
    "    \"6\": \"Sad\",\n",
    "    \"7\": \"Surprised\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55d54bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@voice_router.post(\"/post\")\n",
    "async def classify_audio(file: UploadFile = File(...)):\n",
    "    if not file.content_type.startswith(\"audio\"):\n",
    "        raise HTTPException(status_code=400, detail=\"Invalid file type. Please upload an audio file.\")\n",
    "    contents = await file.read()\n",
    "\n",
    "    \n",
    "    audio_stream = io.BytesIO(contents)\n",
    "\n",
    "    speech, sample_rate = librosa.load(audio_stream, sr=16000)\n",
    "\n",
    "\n",
    "    inputs = processor(\n",
    "        speech,\n",
    "        sampling_rate=sample_rate,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.nn.functional.softmax(logits, dim=1).squeeze().tolist()\n",
    "    prediction = {id2label[str(i)]: round(probs[i], 3) for i in range(len(probs))}\n",
    "\n",
    "    return prediction\n",
    "\n",
    "app.include_router(voice_router, prefix=\"/voice\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e40da9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
